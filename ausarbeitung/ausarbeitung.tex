\documentclass[a4,german]{article}

\usepackage[german]{babel} % für deutsche Silbentrennung und generierte Texte
\usepackage[T1]{fontenc}    % für deutsche Umlaute etc. in der Ausgabe
\usepackage[utf8]{inputenc} % für deutsche Umlaute.
\usepackage{graphicx}       % um Bilder einzubinden
\usepackage{subfigure} 	  % um 2 Bilder nebeneinander haben zu können
\usepackage{hyperref}       % um URLs korrekt einzubinden und Hyperlinks im Dokument zu ermöglichen


\begin{document}

% Titelseite
\begin{titlepage}
\begin{figure}[h]
	\begin{minipage}[b]{62mm}
		\includegraphics[width=59mm]{unilogo.png}
	\end{minipage}
	\hspace{4cm}
	\begin{minipage}[b]{59mm}
           	%\begin{flushright}
            	\includegraphics[width=28mm]{unihh.png}
	\end{minipage}
\end{figure}

\vfill
	
\begin{center}
\noindent { \huge Praktikum Computer Vision\\}
\vspace{14mm}
% Titel
\noindent \textbf{\huge Cloud Computing mal anders: Klassifikation von Wolkenbildern mit kNN und CNNs\\ %oder: Klassifikation von Wolkenarten: Ein Vergleich von verschiedenen Merkmalen zu CNNs
}
\vspace{4mm}
\vfill

 Maximilian Birkenhagen, Ali Ebrahimi, Thilo Fryen, Lukas Hintze \\
~ \\
\today

\vspace{15mm}
\textbf{ \Large{DEPARTMENT} \\ \small{mathematics, informatics \\ and natural science} \\ }	
\vspace{5mm}
\noindent \rule{\textwidth}{0.4mm} %Die Linie

\Large{ZUSAMMENFASSUNG}
\end{center}
\noindent Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\\
\end{titlepage}

\section{Einleitung}

% TODO: Einleitung
%Hier sollte stehen, was under Thema ist, warum es interessant ist, was andere Leute davor schon gemacht haben,
%was unsere Aufgabe ist, und wie unsere Arbeit aufgebaut ist.---

Wir haben uns dafür entschieden, Wolken zu klassifizieren; einerseits aus Neugier, wie gut dies möglich ist, und andererseits einfach aus eigenem Interesse an Wolken.

 Die Klassifikation von Wolken ist aber nicht nur für Wolken-Enthusiasten interessant, sondern spielt auch eine große Rolle bei der Klimaforschung, Wettervorhersagen und Unwetterwarnungen. Allerdings werden dabei eher andere Messmethoden wie Radar, Laser (z.B. LiDAR) oder Radiometer verwendet, bei denen Messungen von Sensoren an verschiedenen Orten (Satellit, Bodenstationen) kombiniert werden \footnote{Whang, Zhien; Sassen, Kenneth: Cloud Type and Macrophysical Property Retrieval Using Multiple Remote Sensors, University of Utah, 2001 - DOI:https://doi.org/10.1175/1520-0450(2001)040<1665:CTAMPR>2.0.CO;2}. Es gab aber auch schon versuche, nur mit Hilfe von Bildern Wolken zu klassifizieren: Forscher der Universität Kiel fotografierten den gesamten Himmel immer wieder von einer Position aus und unterschieden sieben verschiedene Wolkenarten(kombinationen), darunter auch "leerer Himmel". Mithilfe eines k-nearest-neighbour Klassifikators erreichten sie bei der Leave-One-Out Cross-Validation eine Genauigkeit von 97\% \footnote{Heinle, A.; Macke, A.; Srivastav, A.: Automatic cloud classification of whole sky images, Universität Kiel, 2010 - DOI: 10.5194/amt-3-557-2010}.

Unsere Aufgabe war es, Wolken einerseits mit dem 'klassischen' Ansatz und andererseits mittels Convolutional Neural Networks (CNN) zu klassifizieren und die Ergebnisse zu vergleichen. 
Für die Klassifizierung mit dem 'klassischen' Ansatz haben wir verschiedene Merkmale, wie zum Beispiel: Mittelwert, Standabweichung, Farb-Histogramm und Kantenerkennung verwendet.
 
 Dieser Bericht ist so aufgebaut, dass wir erst erklären wo unsere Bilder herkommen, was für Charakteristika sie haben und wie wir diese verarbeitet haben. Danach wird unsere Methodik erläutert, wie wir Probleme gelöst haben und was für Verfahren wir angewendet haben. Sodass zum Schluss ein aussagekräftiges Fazit mit Hinsicht auf unsere Ergebnisse gezogen wurde.
 
Entstanden ist diese Ausarbeitung im Rahmen des Praktikums 'Computervision' an der Universität Hamburg im Sommersemster 2018.



\section{Daten}

% TODO: Daten
%Hier sollte stehen, woher unsere Daten kommen, wie sie aussehen, was für Charakteristika sie haben, und was so klassentypische Einträge sind.

Unsere Bilder haben wir von der Website Wolken-online.de und von der World Meteorological Organization (WMO).
Insgesamt standen uns ca. 800 Bilder zur Verfügung.
Die Bilder waren meist von individuellen Personen geschossene Bilder vom Himmel. 
Allerdings ist auf den Bildern oft nicht nur der Himmel zu sehen, sondern auch am unteren Rand die Erde, zum Beispiel Häuser oder Bäume. Außerdem sind gelegentlich mehrere Wolkenarten auf dem selben Bild vertreten.

Der \textit{International Cloud Atlas} unterscheidet zehn Wolkengattungen, welche in Abbildung~\ref{fig:cloudtypes} schematisch dargestellt sind. Da diese sich untereinander teilweise sehr ähneln und wir lieber weniger Klassen unterscheiden wollen, haben wir diese in vier Hauptgruppen unterteilt.

\begin{figure}[h!]
\centering
\includegraphics[width=10cm,height=13cm,keepaspectratio]{Cloud_infographic-01.png}
\caption{Schematische Darstellung der zehn Wolkengattungen}
    \label{fig:cloudtypes}
\end{figure}

\begin{itemize}
\item Cirriform: Cirrus\\123 Bilder
\item Cumuliform: Cumulus, Cumulonimbus\\294 Bilder
\item Stratiform: Cirrostratus, Altostratus, Nimbostratus, Stratus\\129 Bilder
\item Stratocumuliform: Cirrocumulus, Altocumulus, Stratocumulus\\287 Bilder
\end{itemize}

Die Wolkenarten unterscheiden sich im wesentlichen durch ihre Struktur, Dichte und Höhe, wobei die letzten beiden auf Bildern nur schwer bis nicht erkennbar sind. Die stratiformen Wolken zeichnen sich dadurch aus, dass sie sehr flächig und zusammenhängend sind und meinst durchgängig den ganzen Himmel bedecken. Die Cirriformen Wolken sind gefedert und oft durchsichtig, da sie sehr dünn und gefächert sind. Die cumuliformen Wolken haben die Form von großen Haufen, während die Stratocumuliformen Wolken die Form von vielen kleinen Haufen haben. Leider, wie man auch schon an den Namen der verschiedenen Wolkengattungen sieht, gehen sie ineinander über, was die Unterscheidung deutlich erschwert. Außerdem gibt es noch sehr viele, Arten, Unterarten und Begleitwolken, die sich teilweise auch überschneiden \footnote{Eine gute Übersicht der Wolkengattungen, -arten, etc. findet man unter\\ https://de.wikipedia.org/wiki/Wolke\#Übersicht, zuletzt aufgerufen im August 2018} . 

\section{Methodik}

% TODO: Methodik
%Hier sollte stehen, wie wir unser Problem lösen, sprich, wie unser Endsystem funktioniert.
%Warum machen wir es so und nicht anders?
%Wie funktionieren die Verfahren, die wir nutzen?
%Auch eine Ablaufgrafik wäre nice.

\subsection{Beschaffung der Bilder}
@Lukas , vll  kurz erläutern wie du sie aus deren Website gezogen hast

\subsection{Verwertung der Bilder}
Da die Bilder verschieden waren, mussten wir sie vor der Klassifikation anpassen.
Zuerst haben wir unpassende Bilder, wie zum Beispiel von einem Sturm oder Bilder, auf denen die Wolken kaum erkennbar waren, manuell aussortiert.
Wie erwähnt war oft der untere Rand des Bildes nicht mehr der Himmel, sondern zum Beispiel eine Wiese oder Bäume.
Durch eine Binarisierung konnten wir relativ akkurat den Himmel ausschneiden.
Zum Schluss haben wir die Bilder noch auf die Einheitliche Größe von 500x500 Pixel gebracht, bei welcher die Algorithmen noch schnell ein genaues Ergebnis berechnen konnten. Der Train/Validation-Split beim klassischen Ansatz war 8:2 bzw. 666:167.

\subsubsection{Binarisierung}
Die Binarisierung haben wir mithilfe des arithmetischen Mittels des gesamten Bildes und dem Hue + Value aus dem HSV-Farbraum implementiert.
Ein Pixel gehört somit zum Bild, falls er heller ist als der Durchschnitt des gesamten Bildes, und falls er weder grün noch sehr sehr dunkel ist. Dies hat nach vielem rumexperimentieren für ein gutes Ergebnis gesorgt \ref{fig:boxAlg}. 
\subsubsection{BoxCut Algrotithmus}
Nach dem Binarisieren wird von unten eine rechteckige Fläche des Bildes ausgewählt. Die Höhe beträgt dabei ca. 0.1 des Bildes und die gesamte Breite (dargestellt durch das rote Rechteck im mittleren Bild in \ref{fig:boxAlg}). In dem markierten Rechteck wird dann der durchschnittliche Farbwert berechnet, und falls dieser über unserem Treshhold von 0.35 liegt, gehört ein Teil der Box wahrscheinlich zum Himmel, sodass das Bild bis zum unteren Teil der Box geschnitten wird.
Falls aber der durchschnittliche Farbwert unter dem Treshhold liegt, wird die Box um die Hälfte ihrer Höhe nach oben verschoben, bis dann der Treshhold irgendwann überschritten wird.
Wir haben mit vielen Bilder herumexperimentiert, sodass wir unsere Werte angepasst haben, um beim Großteil auf ein gutes Ergebnis zu kommen.


\begin{figure}[h!]
\centering
\includegraphics[width=1.1\textwidth]{boxAlg} %wäre schön das größer zu bekommen, ohne dass es sich verschiebt 
\caption{BoxCut-Alogorithmus hat den Himmel erfolgreich von der Erde getrennt}
\label{fig:boxAlg}
\end{figure}

\subsubsection{Kantenzählung}
Ein Merkmal, das wir verwenden, misst die Kanten auf den Bildern. Dazu wird zuerst das Bild in ein Graubild umgewandelt, da dann nicht die Kanten für jeden Farbwert (RGB) einzeln berechnet werden müssen. Als nächstes wird ein Gaussfilter mit Sigma = 2 auf das Bild angewendet, damit nur die gröberen Kanten ins Gewicht fallen. Danach wird mit Sobel ein Kantenbild erzeugt. Dort, wo sich Kanten befinden, sind die Pixel heller, d.h. die Werte sind höher. Diese Werte werden dann Zeilenweise summiert, sodass ein Histogramm wie auf dem rechten Bild in Abbildung~\ref{fig:kaz} entsteht. So können die Kanten pro Zeile von zwei Bildern verglichen werden.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{Kantenzählung.png}
\caption{Kantenzählung: Visualisierung der Funktion}
    \label{fig:kaz}
\end{figure}

\subsection{Augmentation der Bilder}
Da wir nur 800 Bilder zur Verfügung hatten, war es besonders für unser Convolutional Neural Network wichtig, mehr Bilder durch Augmentation zu erzeugen.
Hier haben wir uns dafür entschieden, dass nach dem Ausschneiden des Himmels ein Bild jeweils in drei Teile geteilt wird. \ref{fig:augmentation}
Wobei dann die drei Bilder, die aus einem Bild entstanden sind, entweder alle in den Test- oder den Validation-Split kommen mussten.
\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{Augmentation}
\caption{Ein Bild wurde zu drei verschiedenen augmentiert}
    \label{fig:augmentation}
\end{figure}

\subsection{Gescheiterte Ansätze}
Wir hatten noch zusätzliche Merkmale implementiert, die nicht gut genug funktioniert haben, um sie zu verwenden.
Ein Ansatz war das Region Growing bei Wolken, um dann daraus die Zusammenhangskomponenten oder die Frequenzen der Regionen abzuleiten.
Besonders bei der Klassifizierung von  "Schäfchenwolken", wäre die Anzahl der Zusammenhangskomponenten aussagekräftig gewesen.
Wir konnten Region Growing leider nicht benutzen, da auf vielen Bildern die Wolken ineinander übergehen und trotz Runterskalierung auf 50p x 50p, hat die Berechnung noch bis zu 30 Sekunden gedauert.



\section{Experimente und Ergebnisse}

\subsection{Klassischer Ansatz}%TODO: Daten bei Änderungen aktualisieren
Die höchste Genauigkeit, die wir mit dem klassischen Ansatz erzielen konnten, beträgt 49\%. Wie gut dabei die einzelnen Merkmale abschneiden, kann man aus Tabelle~\ref{tab:gen} herauslesen. Dabei steht \textit{mean} für den Mittelwert und \textit{std} für die Standardabweichung. 
\begin{table}[h]
\begin{tabular}{|l|l|l|l|l|l|l|}
 \hline
 \textbf{Merkmale:}&mean&std&1D-Hist.&3D-Hist.&Grau-Hist.&Kantenz.\\
 \hline
 \textbf{Erfolg:} & 28\% & 32\% & 35\% & 38\% & grau & 41\% \\
 \hline
\end{tabular}
\caption{Genauigkeit der einzelnen Merkmale, gerundet}
\label{tab:gen}
\end{table}

\begin{table}[h]
\begin{tabular}{|l|l|l|l|}
 \hline
 \textbf{Kombi.:}&mean+std&mean+std+Kantenz.&Kantenz.+3D-Hist.\\
 \hline
 \textbf{Erfolg:} & 40\% & 48\% & 49\% \\
 \hline
\end{tabular}
\caption{Genauigkeit von Merkmalskombinationen, gerundet}
\label{tab:gen2}
\end{table}

Abbildung~\ref{fig:meanstd} zeigt, dass die verschiedenen Klassen mithilfe von Mittelwert und Standardabweichung nur schwer auseinanderzuhalten sind. Trotzdem erreichen wir hier eine Genauigkeit von 40\%.
\begin{figure}[h!]
\centering
\includegraphics[width=1.1\textwidth]{Scatterplot_mean_std.png} %wäre schön das größer zu bekommen, ohne dass es sich verschiebt 
\caption{Scatterplot für Mittelwert und Standardabweichung}
\label{fig:meanstd}
\end{figure}

Bei der Kantenzählung wurden beim Gaussschen Weichzeichner Sigma ausprobiert, wobei sich Sigma = 2 als am besten herausstellte (siehe Tabelle~\ref{tab:sigma}). Dies ist so, da bei größeren Sigmas die Kanten zu sehr verschwimmen %<-- Bin mir da nicht 100% sicher, ob das stimmt, weil ich nicht weiß, ob ich Sigma richtig verstanden habe...
\begin{table}[h]
\begin{tabular}{|l|l|l|l|l|l|}
 \hline
 \textbf{Sigma:} & 0 & 1 & 2 & 3 & 4\\
 \hline
 \textbf{Erfolg:} & 40\% & 41\% & 41\% & 36\% & 35\% \\
 \hline
\end{tabular}
\caption{Genauigkeit der Kantenzählung bei verschiedenen Sigmas für den Weichzeichner}
\label{tab:sigma}
\end{table}
Die Kantenzählung war besonders darauf ausgelegt, stratiforme Wolken (flächige Wolken) zu identifizieren, da diese meist durchgängige Flächen sind und daher wenig Kanten haben. Abbildung~\ref{fig:kbs} zeigt einen Boxplot und einen Swarmplot für die Kantenzählung. Dabei ist wichtig zu berücksichtigen, dass für die Plots die Histogramme auf einen Wert reduziert wurden, das heißt der Plot spiegelt das Merkmal nur näherungsweise wieder. Während der Boxplot vermuten lässt, die stratiformen Wolken ließen sich mithilfe des Merkmals klar von den anderen trennen, zeigt der Swarmplot, dass dies nur für etwa die Hälfte der Bilder mit stratiformen Wolken gilt. %Also haben wir das Merkmal so für unseren Entscheidungsbaum verwendet, dass wir alle Wolken die einen Gesamtkantenwert von unter 1000 haben als stratiform klassifizieren, dabei aber nicht ausschließen, dass unter den Verbliebenen noch stratiforme Wolken sind...könnte man hier schreiben wenn wir es machen.


\begin{figure}[h!]%Die Bilder sind eventuell zu klein, dann bitte einfach untereinander statt nebeneinander.
\subfigure[Boxplot Kantenzählung]
{\includegraphics[width=0.53\textwidth]{edge_count_boxplot.png}}
\subfigure[Swarmplot Kantenzählung]
{\includegraphics[width=0.53\textwidth]{edge_count_swarmplot.png}}
\caption{Kantenzählung: Unterschiede der Klassen}
    \label{fig:kbs}
\end{figure}

\subsection{Neuronale Netze}
% TODO: Fazit
%Wie sehen unsere Ergebnisse aus?
%Wie verändern sich die Ergebnisse durch die CNNs?
%Was passiert, wenn man einzelne Teile des Systems austauscht oder Merkmale entfernt (dies evtl.\ auch mit Diagrammen zeigen)?
%Wie schneidet das System pro Klasse ab?
%Wie wirken sich Änderungen der Parameter/Hyperpara\-meter auf die Ergebnisse aus?
%Wie schnell sind unsere Verfahren?

\subsection{Menschen klassifizieren Wolken}
Da uns aufgefallen ist, dass es nicht nur für den Computer sondern auch für uns schwierig ist, die Wolken zu klassifizieren, haben wir uns dazu entschieden, eine Studie durchzuführen. Bei dieser Studie sollten die sechs Probanden jeweils sechzehn Wolkenbilder in unsere vier Kategorien einteilen. Sie haben die Übersicht aus Abbildung~\ref{fig:cloudtypes} bekommen und pro Klasse sechs Trainingsbilder als Referenz. Dabei wurde eine Durchschnittliche Genauigkeit von 51\% erreicht. Der Versuchsaufbau und die Ergebnisse sind noch einmal genauer in Anhang 1%oder der wievielte Anhang auch immer.. bitte aktualisieren/korrigieren
geschildert.

\section{Fazit}

% TODO: Fazit
%Was ist unser Fazit?
%Zusammenfassung und Einordnung unserer Ergebnisse.
%Ausblick?

Insgesamt können wir sagen, dass es eine Herausforderung war, die verschiedenen Bilder zu klassifizieren. Vor allem weil artenexterne Bilder sich teilweise so ähnlich, aber auch die arteninternen Bilder so unterschiedlich aussahen. Und da es sogar für Menschen schwer ist, viele Bilder zu unterscheiden, hatten wir besonders bei der klassischen Methode nicht all zu genaue Ergebnisse erwartet.
Allerdings sind wir mit 49\% sind wir schon sehr zufrieden, da das noch weit besser als zufälliges Zuordnen der Klassen ist.
Beim Neuronale Netze ....

Wir könnten uns vorstellen, dass ein viel besseres Ergebnis zu erreichen ist, wenn die Bilder alle nach einer bestimmten Norm aufgenommen wären, zum Beispiel mit dem selben Winkel zum Himmel, bei Gleicher Helligkeit, vom selben Standpunkt aus, etc. Allerdings müsste man dann vorsichtig sein, wie im Falle der Kieler Universität, das die Bilder nicht overfitten. 

% Literaturverzeichnis mit Hilfe der "thebibliography" Umgebung:

\begin{thebibliography}{99}
	
% Beispiel für ein Buch
\bibitem {mustermann1234} M. Mustermann. \textit{Das hier ist nur ein Beispiel}. Musterverlag, 1234.

\end{thebibliography}



\end{document}
